{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e77417-de63-43b0-b198-30d64c88b3c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['model_year'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m encoded_test\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df_test\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Concatenate encoded categorical columns with numerical columns\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_columns\u001b[49m\u001b[43m]\u001b[49m, encoded_train], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_test[numerical_columns], encoded_test], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Align the columns between train and test sets to avoid issues with different columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['model_year'] not in index\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Load CSV files\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Drop the 'id' column as it's not useful\n",
    "df_train = df_train.drop(columns=['id'])\n",
    "id_test = df_test['id']\n",
    "df_test = df_test.drop(columns=['id'])\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "categorical_columns = ['brand', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
    "numerical_columns = df_train.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_columns.remove('price')  # Don't include target\n",
    "\n",
    "# Step 1: Handle missing values before feature engineering\n",
    "\n",
    "# KNN Imputer for both numerical and categorical features (categoricals should be encoded later)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_train_imputed = knn_imputer.fit_transform(df_train[numerical_columns])\n",
    "X_test_imputed = knn_imputer.transform(df_test[numerical_columns])\n",
    "\n",
    "# Reintegrating the imputed numerical data back into the DataFrame\n",
    "df_train[numerical_columns] = X_train_imputed\n",
    "df_test[numerical_columns] = X_test_imputed\n",
    "\n",
    "# Step 2: Feature engineering (after handling missing values)\n",
    "\n",
    "# Add car age and drop model_year\n",
    "df_train['car_age'] = 2024 - df_train['model_year']\n",
    "df_test['car_age'] = 2024 - df_test['model_year']\n",
    "df_train.drop('model_year', axis=1, inplace=True)\n",
    "df_test.drop('model_year', axis=1, inplace=True)\n",
    "\n",
    "# Target encoding for 'model' to avoid high cardinality\n",
    "mean_price_per_model = df_train.groupby('model')['price'].mean()\n",
    "df_train['model'] = df_train['model'].map(mean_price_per_model)\n",
    "df_test['model'] = df_test['model'].map(mean_price_per_model)\n",
    "\n",
    "# Extract engine power and cylinder\n",
    "df_train['engine_power'] = df_train['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
    "df_test['engine_power'] = df_test['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
    "\n",
    "df_train['engine_cylinder'] = df_train['engine'].str.extract(r'(\\d+\\.?\\d*)L').astype(float)\n",
    "df_test['engine_cylinder'] = df_test['engine'].str.extract(r'(\\d+\\.?\\d*)L').astype(float)\n",
    "\n",
    "# Remove the 'engine' column after extraction\n",
    "df_train.drop('engine', axis=1, inplace=True)\n",
    "df_test.drop('engine', axis=1, inplace=True)\n",
    "\n",
    "# Regroup rare colors in 'ext_col' and 'int_col'\n",
    "color_threshold = 100\n",
    "ext_color_counts = df_train['ext_col'].value_counts()\n",
    "rare_ext_colors = ext_color_counts[ext_color_counts < color_threshold].index\n",
    "df_train['ext_col'] = df_train['ext_col'].replace(rare_ext_colors, 'Other')\n",
    "df_test['ext_col'] = df_test['ext_col'].replace(rare_ext_colors, 'Other')\n",
    "\n",
    "int_color_counts = df_train['int_col'].value_counts()\n",
    "rare_int_colors = int_color_counts[int_color_counts < color_threshold].index\n",
    "df_train['int_col'] = df_train['int_col'].replace(rare_int_colors, 'Other')\n",
    "df_test['int_col'] = df_test['int_col'].replace(rare_int_colors, 'Other')\n",
    "\n",
    "# Step 3: Drop any newly created missing values from feature engineering\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# OneHotEncode only for categorical columns with low cardinality\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns\n",
    "encoded_train = pd.DataFrame(encoder.fit_transform(df_train[categorical_columns]))\n",
    "encoded_test = pd.DataFrame(encoder.transform(df_test[categorical_columns]))\n",
    "\n",
    "# Add column names to encoded data\n",
    "encoded_train.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "encoded_test.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "# Reset index to align encoded data with original data\n",
    "encoded_train.index = df_train.index\n",
    "encoded_test.index = df_test.index\n",
    "\n",
    "# Concatenate encoded categorical columns with numerical columns\n",
    "X_train = pd.concat([df_train[numerical_columns], encoded_train], axis=1)\n",
    "X_test = pd.concat([df_test[numerical_columns], encoded_test], axis=1)\n",
    "\n",
    "# Align the columns between train and test sets to avoid issues with different columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Apply RobustScaler to numerical columns\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Target variable\n",
    "y_train = df_train['price']\n",
    "\n",
    "# Apply Box-Cox transformation to target variable (price)\n",
    "y_train_boxcox, lambda_ = boxcox(y_train)  # No need to add 1 if prices are strictly positive\n",
    "\n",
    "# Train-test split for evaluation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_scaled, y_train_boxcox, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10cc5d-4c08-4eeb-9e27-accc78d9873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using a simple model like Ridge to evaluate\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train_split, y_train_split)\n",
    "y_pred_boxcox = ridge_model.predict(X_val)\n",
    "\n",
    "# Inverse Box-Cox transformation to get predictions back to the original scale\n",
    "y_pred = inv_boxcox(y_pred_boxcox, lambda_)\n",
    "\n",
    "# RMSE evaluation in the original scale\n",
    "rmse = np.sqrt(mean_squared_error(inv_boxcox(y_val, lambda_), y_pred))\n",
    "print(f'Ridge Model RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90cb22ef-e3b3-433b-bd96-404aa271ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Drop the 'id' column as it's not useful\n",
    "df_train = df_train.drop(columns=['id'])\n",
    "id_test = df_test['id']\n",
    "df_test = df_test.drop(columns=['id'])\n",
    "\n",
    "# Add car age and drop model_year\n",
    "df_train['car_age'] = 2024 - df_train['model_year']\n",
    "df_test['car_age'] = 2024 - df_test['model_year']\n",
    "df_train.drop('model_year', axis=1, inplace=True)\n",
    "df_test.drop('model_year', axis=1, inplace=True)\n",
    "\n",
    "# Rebuild the numerical columns list without 'model_year'\n",
    "numerical_columns = df_train.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_columns.remove('price')  # Don't include the target\n",
    "\n",
    "# Separate categorical columns for encoding\n",
    "categorical_columns = ['brand', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
    "\n",
    "# Handle missing values before feature engineering\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_train_imputed = knn_imputer.fit_transform(df_train[numerical_columns])\n",
    "X_test_imputed = knn_imputer.transform(df_test[numerical_columns])\n",
    "\n",
    "# Reintegrating the imputed numerical data back into the DataFrame\n",
    "df_train[numerical_columns] = X_train_imputed\n",
    "df_test[numerical_columns] = X_test_imputed\n",
    "\n",
    "# OneHotEncode only for categorical columns with low cardinality\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns in train and test\n",
    "encoded_train = pd.DataFrame(encoder.fit_transform(df_train[categorical_columns]))\n",
    "encoded_test = pd.DataFrame(encoder.transform(df_test[categorical_columns]))\n",
    "\n",
    "# Add column names to encoded data\n",
    "encoded_train.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "encoded_test.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "# Reset index to align encoded data with original data\n",
    "encoded_train.index = df_train.index\n",
    "encoded_test.index = df_test.index\n",
    "\n",
    "# Concatenate encoded categorical columns with numerical columns\n",
    "X_train = pd.concat([df_train[numerical_columns], encoded_train], axis=1)\n",
    "X_test = pd.concat([df_test[numerical_columns], encoded_test], axis=1)\n",
    "\n",
    "# Align the columns between train and test sets to avoid issues with different columns\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Apply RobustScaler to numerical columns\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Target variable\n",
    "y_train = df_train['price']\n",
    "\n",
    "# Apply Box-Cox transformation to target variable (price)\n",
    "y_train_boxcox, lambda_ = boxcox(y_train)  # No need to add 1 if prices are strictly positive\n",
    "\n",
    "# Train-test split for evaluation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_scaled, y_train_boxcox, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322a15f0-931a-4b86-898e-b9ba72b4e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - RMSE: 76007.05061082898\n",
      "ElasticNet - RMSE: 76007.05061082898\n",
      "Random Forest - RMSE: 69636.59025929742\n",
      "Gradient Boosting - RMSE: 69912.58285707333\n",
      "XGBoost - RMSE: 69295.07711191328\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1135\n",
      "[LightGBM] [Info] Number of data points in the train set: 150826, number of used features: 425\n",
      "[LightGBM] [Info] Start training from score 8.698397\n",
      "LightGBM - RMSE: 69319.42656435727\n",
      "CatBoost - RMSE: 69232.44833854595\n"
     ]
    }
   ],
   "source": [
    "# Import necessary regressors\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create a dictionary of models\n",
    "models = {\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(),\n",
    "    \"LightGBM\": LGBMRegressor(),\n",
    "    \"CatBoost\": CatBoostRegressor(silent=True),  # Silent=True to suppress verbose output\n",
    "}\n",
    "\n",
    "# Loop to train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    y_pred_boxcox = model.predict(X_val)\n",
    "    \n",
    "    # Inverse Box-Cox transformation to get predictions back to original scale\n",
    "    y_pred = inv_boxcox(y_pred_boxcox, lambda_)\n",
    "    \n",
    "    # Calculate RMSE on validation set\n",
    "    rmse = np.sqrt(mean_squared_error(inv_boxcox(y_val, lambda_), y_pred))\n",
    "    \n",
    "    print(f\"{name} - RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c04053-2d76-402c-a4a4-6d8d73be5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=  CatBoostRegressor(silent=True)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "y_pred_transformed = model.predict( X_test)\n",
    "    \n",
    " # Inverser la transformation Box-Cox\n",
    "y_pred = inv_boxcox(y_pred_transformed, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1e0547-2fbb-45fa-a053-c9db967db4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Création du fichier de soumission\n",
    "submission_df = pd.DataFrame({'id': id_test, 'price': y_pred})\n",
    "submission_df.to_csv('submission_nv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10daa95f-bec6-4d48-911e-7ad07ae3da8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
